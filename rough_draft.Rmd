---
title: "Rough Draft"
author: "Brian Pennington"
date: "December 2, 2016"
output: html_document
---

```{r}
library(tidyverse)
library(tidytext)
library(rvest)
library(stringr)
library(feather)
library(topicmodels)
library(knitr)
library(SnowballC)
library(tm)
library(wordcloud)
set.seed(1234)
```

```{r}
get_Trump_speeches <- function(x){
  text_url = str_c("http://www.presidency.ucsb.edu/ws/index.php?pid=", x)

  df1 <- read_html(text_url) %>%
    html_nodes("p") %>%
    html_text()
  
  df2 <- read_html(text_url)%>%
    html_node(".docdate")%>%
    html_text()
  
  
  speech <- data_frame(text = df1) %>%
    mutate(author = "Trump",
           parnumber = row_number(),
           date = df2) %>%
    separate(date, into = c("date2", "year"), sep = ",") %>%
    separate(date2, into = c("month", "day"), sep = " ")
  speech <- unnest_tokens(speech, word, text, token = "words")  
  return(speech)
}  

x = c(
  "119182",  
  "119181",
  "119188",
  "119187",
  "119186",  
  "119185",  
  "119184",  
  "119183",
  "119174",
  "119172",  
  "119180",  
  "119173",  
  "119170",  
  "119169",  
  "119168",  
  "119167",  
  "119166",  
  "119179",  
  "119202",  
  "119201",  
  "119200",  
  "119203",  
  "119191",  
  "119189",  
  "119192",  
  "119207",  
  "119208",  
  "119209", 
  "119190",  
  "119206",  
  "119206",  
  "119193",  
  "119205",  
  "119178",  
  "119204",  
  "119194",  
  "119195",  
  "119177",  
  "119197",  
  "119199",  
  "119198",  
  "119196",  
  '119176',  
  "119175",  
  "119165",  
  "119503",  
  "117935",  
  "117791",  
  "117815",  
  "117790",  
  "117775",  
  "117813",  
  "116597")

Trump_Corpus <- map_df(x, get_Trump_speeches, .id = "docnumber")



write_feather(Trump_Corpus, "corpus/Trump_Corpus.feather")
```


```{r}
get_Clinton_speeches <- function(x){
  text_url = str_c("http://www.presidency.ucsb.edu/ws/index.php?pid=", x)
  
  df1 <- read_html(text_url) %>%
    html_nodes("p") %>%
    html_text()
  
  df2 <- read_html(text_url)%>%
    html_node(".docdate")%>%
    html_text()
  
  
  speech <- data_frame(text = df1) %>%
    mutate(author = "Clinton",
           parnumber = row_number(),
           date = df2) %>%
    separate(date, into = c("date2", "year"), sep = ",") %>%
    separate(date2, into = c("month", "day"), sep = " ")
  speech <- unnest_tokens(speech, word, text, token = "words")  
  return(speech)
}

#2016 Clinton Presidential Campaign Speeches
#Clinton1 is Nov 3, 2016 - Clinton31 is Dec 15, 2015 

h <- c("119498",
       "119502",
       "119501",
       "119500",
       "119499",
       "119497",
       "119157",
       "119156",
       "119155",
       "119154",
       "119153",
       "119152",
       "119151",
       "119150",
       "119149",
       "119164",
       "119163",
       "119162",
       "119161",
       "119160",
       "119159",
       "119158",
       "119148",
       "118051",
       "119295",
       "116600",
       "111596",
       "111439",
       "111414",
       "111415",
       "119292",
       "111418",
       "111419",
       "110267",
       "110269",
       "110268")

Clinton_Corpus <- map_df(h, get_Clinton_speeches, .id = "docnumber")

write_feather(Clinton_Corpus, "corpus/Clinton_Corpus.feather")
```

```{r}
get_Sanders_speeches <- function(x){
  text_url = str_c("http://www.presidency.ucsb.edu/ws/index.php?pid=", x)
  
  df1 <- read_html(text_url) %>%
    html_nodes("p") %>%
    html_text()
  
  df2 <- read_html(text_url)%>%
    html_node(".docdate")%>%
    html_text()
  
  
  speech <- data_frame(text = df1) %>%
    mutate(author = "Sanders",
           parnumber = row_number(),
           date = df2) %>%
    separate(date, into = c("date2", "year"), sep = ",") %>%
    separate(date2, into = c("month", "day"), sep = " ")
  speech <- unnest_tokens(speech, word, text, token = "words")  
  return(speech)
}  

s <- c("118045", 
       "117194", 
       "117513", 
       "116694", 
       "117516", 
       "117511", 
       "111440", 
       "117514", 
       "117512", 
       "114496", 
       "114487", 
       "117517", 
       "114493", 
       "114491", 
       "114486", 
       "114488", 
       "114494") 

Sanders_Corpus <- map_df(s,get_Sanders_speeches, .id = "docnumber")

write_feather(Sanders_Corpus, "corpus/Sanders_Corpus.feather")
```

```{r}
get_Repub_speeches <- function(x){
  text_url = str_c("http://www.presidency.ucsb.edu/ws/index.php?pid=", x)
  
  df1 <- read_html(text_url) %>%
    html_nodes("p") %>%
    html_text()
  
  df2 <- read_html(text_url)%>%
    html_node(".docdate")%>%
    html_text()
  
  
  speech <- data_frame(text = df1) %>%
    mutate(author = "Cruz/Kasich/Rubio",
           parnumber = row_number(),
           date = df2) %>%
    separate(date, into = c("date2", "year"), sep = ",") %>%
    separate(date2, into = c("month", "day"), sep = " ")
  speech <- unnest_tokens(speech, word, text, token = "words")  
  return(speech)
}  

r <- c("118041",
       "117232",
       "116598",
       "114768",
       "111441",
       "116599",
       "113069")

Repub_Corpus <- map_df(r, get_Repub_speeches, .id = "docnumber")

write_feather(Repub_Corpus, "corpus/Repub_Corpus.feather")
```

```{r}
read_feather("corpus/Trump_Corpus.feather")
read_feather("corpus/Clinton_Corpus.feather")
read_feather("corpus/Sanders_Corpus.feather")
read_feather("corpus/Repub_Corpus.feather")


speech_corpus <- bind_rows(Trump_Corpus, Clinton_Corpus, Sanders_Corpus, Repub_Corpus)


speech_corpus %>%
  group_by(author) %>%
  count(word) %>%
  summarise(total = sum(n))

speech_corpus %>%
  group_by(author) %>%
  filter(word == "applause" | word == "cheers")%>%
  count() %>%
  kable()

speech_corpus %>%
  group_by(author, docnumber) %>%
  filter(word == "applause" | word == "cheers") %>%
  count(docnumber) %>%
  mutate(n_per_speech = n / n()) %>%
  ggplot(aes(docnumber, n_per_speech, fill = author))+
  geom_bar(stat = "identity", alpha = .8)

size <- speech_corpus %>%
  mutate(word_szie = nchar(word)) %>%
  group_by(author) %>%
  count(word_szie) %>%
  mutate(percent = n/sum(n))

size %>%
  ggplot(aes(word_szie, percent, fill= author)) +
  geom_bar(stat = "identity") +
  facet_wrap(~author)
```

```{r}
read_feather("corpus/Trump_Corpus.feather")
read_feather("corpus/Clinton_Corpus.feather")
read_feather("corpus/Sanders_Corpus.feather")
read_feather("corpus/Repub_Corpus.feather")

speech_corpus <- bind_rows(Trump_Corpus, Clinton_Corpus, Sanders_Corpus, Repub_Corpus)
```


Inserting Sentiment
```{r}
speech_corpus_bing <- speech_corpus %>%
  inner_join(get_sentiments("bing"))
#83936 - 10608 = number of words discarded
speech_corpus_affin <- speech_corpus %>%
  inner_join(get_sentiments("afinn"))
#83936 - 11562 = number of words we discarded 
speech_corpus_nrc <- speech_corpus %>%
  inner_join(get_sentiments("nrc"))
#83936 - 43920 = number of words we discarded
```

```{r}
speech_corpus_bing %>%
  count(author, sentiment) %>%
  mutate(percent= n/sum(n))%>%
  print()%>%
  ggplot(aes(author, percent, fill= author)) +
  geom_bar(alpha = .75, stat = "identity", width = .5 )+
  facet_grid(~sentiment)+
  labs(x= "Speaker",
       y= "Percentage of Text") +
  coord_flip()

speech_corpus_nrc %>%
  count(author, sentiment) %>%
  mutate(percent = n/sum(n)) %>%
  print()%>%
  ggplot(aes(sentiment, percent, fill= sentiment)) +
  geom_bar(alpha = .8, stat = "identity")+
  facet_wrap(~author) +
  coord_flip()

 
speech_corpus_nrc %>%
  count(author, sentiment) %>%
  mutate(percent= n/sum(n)) %>%
  ggplot(aes(sentiment, percent)) +
  geom_freqpoly(aes(color= author, group= author), stat = "identity")


speech_corpus_nrc %>%
  count(sentiment, author) %>%
  group_by(sentiment) %>%
  mutate(percent = n/sum(n)) %>%
  print() %>%
  ggplot(aes(author, percent, fill= author)) +
  geom_bar(stat = "identity", alpha = .85, show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free") +
  coord_flip() +
  labs(x = "sentiment",
       y= "% of Sentiment Between Candidates")


speech_corpus_affin %>%
  group_by(author, docnumber) %>%
  mutate(numeric_sentiment = cumsum(score)) %>%
  mutate(percent = as.integer(docnumber)) %>%
  mutate(percent= cumsum(percent/sum(percent))) %>%
  ggplot(aes(percent, numeric_sentiment, color = docnumber))+
  geom_freqpoly(stat = "identity") +
  facet_wrap(~author) +
  geom_line(aes(y = 75), size =2.25, linetype = 2)
```

#Important for producing a readable table with the results for the final project
#This provide tangible 
speech_corpus_affin %>%
  group_by(author, docnumber) %>%
  summarize(sum(score))
  
speech_corpus_affin %>%
  group_by(author, docnumber, month, year) %>%
  summarize(sum(score)) %>%
  group_by(author, month, year) %>%
  mutate(sum_sent = )


```{r}
read_feather("corpus/Trump_Corpus.feather")
read_feather("corpus/Clinton_Corpus.feather")
read_feather("corpus/Sanders_Corpus.feather")
read_feather("corpus/Repub_Corpus.feather")


speech_corpus <- bind_rows(Trump_Corpus, Clinton_Corpus, Sanders_Corpus, Repub_Corpus)

mystopwords2 <- data_frame(word = c("texas", "smith", "cooper", "tianna", "barbara", "freia", "ruline", "miami", "reid", "caroline", "smith", "netanyahu", "michael", "gordon", "gordy", "sharansky", "don't", "that's", "they're", "we're", "mcdowell", "steve", "milwaukee", "maine", "jackson", "indiana", "iowa", "september", "dr", "al", "gabby", "jack", "ben", "vermont", "people", "cheers"))
mystopwords2 <- bind_rows(stop_words, mystopwords2)

word_cloud <- speech_corpus %>%
  select(word) %>%
  filter(word != "applause") %>%
  anti_join(mystopwords2)%>%
  count(word) 
wordcloud(words = word_cloud$word, freq = word_cloud$n, min.freq = 2, 
          max.words = 200, random.order = FALSE, rot.per = 0.5, 
          color=brewer.pal(6, "Dark2"))



speech_td <- speech_corpus %>%
  group_by(author, docnumber) %>%
  filter(word != "applause") %>%
  count(word) %>%
  select(author, word, n, docnumber) %>%
  mutate(docid = paste0(author, docnumber)) %>%
  anti_join(mystopwords2)
speech_td


speech_dtm <- speech_td %>%
  cast_dtm(term = word,value = n, document = docid)
speech_dtm 

speech_lda <- LDA(speech_dtm, k = 4, control = list())
speech_lda

speech_lda_td <- tidy(speech_lda)

top_terms <- speech_lda_td %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
top_terms

perplexity(speech_lda)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic)))+
    geom_bar(stat= "identity", show.legend = FALSE)+
    facet_wrap(~topic, scales = "free")+
    coord_flip()

n_topics <- c(2, 3, 4, 5, 10, 15, 25, 50)
perplexity_comp <- n_topics %>%
  map(LDA, x = speech_dtm, control = list())
data_frame(k = n_topics,
           perplex = map_dbl(perplexity_comp, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line()

speech_lda2 <- LDA(speech_dtm, k = 15, control = list())
speech_lda

speech_lda_td2 <- tidy(speech_lda2)

top_terms2 <- speech_lda_td2 %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
top_terms2

perplexity(speech_lda2)

top_terms2 %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic)))+
  geom_bar(stat= "identity", show.legend = FALSE)+
  facet_wrap(~topic, scales = "free")+
  coord_flip()

inverse_doc_freq <- speech_td %>%
  bind_tf_idf(word, docid, n) %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word))))
inverse_doc_freq


ggplot(inverse_doc_freq[1:25,], aes(word, tf_idf, fill = author)) +
  geom_bar(alpha = 0.8, stat = "identity", scales = "free") +
  coord_flip()

inverse_doc_freq %>%
  group_by(author) %>%
  top_n(20)%>%
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = author)) +
  geom_bar(stat = "identity") +
  facet_wrap(~author, scales = "free") +
  coord_flip()
```

```{r}
read_feather("corpus/Trump_Corpus.feather")

mystopwords2 <- data_frame(word = c("texas", "smith", "cooper", "tianna", "barbara", "freia", "ruline", "miami", "reid", "caroline", "smith", "netanyahu", "michael", "gordon", "gordy", "sharansky", "don't", "that's", "they're", "we're", "mcdowell", "steve", "milwaukee", "maine", "jackson", "indiana", "iowa", "september", "dr", "al", "gabby", "jack", "ben", "vermont", "people", "cheers"))
mystopwords2 <- bind_rows(stop_words, mystopwords2)

Trump_word_cloud <- Trump_Corpus %>%
  select(word) %>%
  filter(word != "applause") %>%
  anti_join(mystopwords2)%>%
  count(word) 
wordcloud(words = Trump_word_cloud$word, freq = Trump_word_cloud$n, min.freq = 2, 
          max.words = 200, random.order = FALSE, rot.per = 0.15, 
          color=brewer.pal(6, "Dark2"))


Trump_td <- Trump_Corpus %>%
  group_by(docnumber) %>%
  filter(word != "applause") %>%
  count(word) %>%
  select(word, n, docnumber)
Trump_td

Trump_dtm <- Trump_td %>%
  anti_join(mystopwords2) %>%
  cast_dtm(term = word,value = n, document = docnumber)
Trump_dtm 

n_topics <- c(2, 3, 4, 5, 10, 15, 25, 50)
Trump_comp <- n_topics %>%
  map(LDA, x = Trump_dtm, control = list())
data_frame(k = n_topics,
           perplex = map_dbl(Trump_comp, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line()

trump_lda <- LDA(Trump_dtm, k = 15, control = list())
trump_lda

trump_lda_td <- tidy(trump_lda)

trump_terms <- trump_lda_td %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
trump_terms

perplexity(speech_lda)

trump_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic)))+
  geom_bar(stat= "identity", show.legend = FALSE)+
  facet_wrap(~topic, scales = "free")+
  coord_flip()
```

```{r}
read_feather("corpus/Clinton_Corpus.feather")

mystopwords2 <- data_frame(word = c("texas", "smith", "cooper", "tianna", "barbara", "freia", "ruline", "miami", "reid", "caroline", "smith", "netanyahu", "michael", "gordon", "gordy", "sharansky", "don't", "that's", "they're", "we're", "mcdowell", "steve", "milwaukee", "maine", "jackson", "indiana", "iowa", "september", "dr", "al", "gabby", "jack", "ben", "vermont", "people", "cheers"))
mystopwords2 <- bind_rows(stop_words, mystopwords2)

clinton_word_cloud <- Clinton_Corpus %>%
  select(word) %>%
  filter(word != "applause") %>%
  anti_join(mystopwords2)%>%
  count(word) 
wordcloud(words = clinton_word_cloud$word, freq = clinton_word_cloud$n, min.freq = 2, 
          max.words = 200, random.order = FALSE, rot.per = 0.15, 
          color=brewer.pal(6, "Dark2"))

Clinton_td <- Clinton_Corpus %>%
  group_by(docnumber) %>%
  filter(word != "applause") %>%
  count(word) %>%
  select(word, n, docnumber)
Clinton_td

Clinton_dtm <- Clinton_td %>%
  anti_join(mystopwords2) %>%
  cast_dtm(term = word,value = n, document = docnumber)
Clinton_dtm 

n_topics <- c(2, 3, 4, 5, 10, 15, 25, 50)
Clinton_comp <- n_topics %>%
  map(LDA, x = Clinton_dtm, control = list())
data_frame(k = n_topics,
           perplex = map_dbl(Clinton_comp, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line()

clinton_lda <- LDA(Clinton_dtm, k = 15, control = list())
clinton_lda

clinton_lda_td <- tidy(clinton_lda)

clinton_terms <- clinton_lda_td %>%
  group_by(topic) %>%
  top_n(7, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
clinton_terms

perplexity(clinton_lda)

clinton_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic)))+
  geom_bar(stat= "identity", show.legend = FALSE)+
  facet_wrap(~topic, scales = "free")+
  coord_flip()
```

```{r}
read_feather("corpus/Sanders_Corpus.feather")

mystopwords2 <- data_frame(word = c("texas", "smith", "cooper", "tianna", "barbara", "freia", "ruline", "miami", "reid", "caroline", "smith", "netanyahu", "michael", "gordon", "gordy", "sharansky", "don't", "that's", "they're", "we're", "mcdowell", "steve", "milwaukee", "maine", "jackson", "indiana", "iowa", "september", "dr", "al", "gabby", "jack", "ben", "vermont", "people", "cheers"))
mystopwords2 <- bind_rows(stop_words, mystopwords2)

sanders_word_cloud <- Sanders_Corpus %>%
  select(word) %>%
  filter(word != "applause") %>%
  anti_join(mystopwords2)%>%
  count(word) 
wordcloud(words = sanders_word_cloud$word, freq = sanders_word_cloud$n, min.freq = 2, 
          max.words = 200, random.order = FALSE, rot.per = 0.35, 
          color=brewer.pal(6, "Dark2"))

Sanders_td <- Sanders_Corpus %>%
  group_by(docnumber) %>%
  filter(word != "applause") %>%
  count(word) %>%
  select(word, n, docnumber)
Sanders_td

Sanders_dtm <- Sanders_td %>%
  anti_join(mystopwords2) %>%
  cast_dtm(term = word,value = n, document = docnumber)
Sanders_dtm 

n_topics <- c(2, 3, 4, 5, 10, 15, 25, 50)
Sanders_comp <- n_topics %>%
  map(LDA, x = Sanders_dtm, control = list())
data_frame(k = n_topics,
           perplex = map_dbl(Sanders_comp, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line()

sanders_lda <- LDA(Sanders_dtm, k = 15, control = list())
sanders_lda

sanders_lda_td <- tidy(sanders_lda)

sanders_terms <- sanders_lda_td %>%
  group_by(topic) %>%
  top_n(7, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
sanders_terms

perplexity(sanders_lda)

sanders_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic)))+
  geom_bar(stat= "identity", show.legend = FALSE)+
  facet_wrap(~topic, scales = "free")+
  coord_flip()
```

```{r}
read_feather("corpus/Repub_Corpus.feather")

mystopwords2 <- data_frame(word = c("texas", "smith", "cooper", "tianna", "barbara", "freia", "ruline", "miami", "reid", "caroline", "smith", "netanyahu", "michael", "gordon", "gordy", "sharansky", "don't", "that's", "they're", "we're", "mcdowell", "steve", "milwaukee", "maine", "jackson", "indiana", "iowa", "september", "dr", "al", "gabby", "jack", "ben", "vermont", "people", "cheers"))
mystopwords2 <- bind_rows(stop_words, mystopwords2)

repub_word_cloud <- Repub_Corpus %>%
  select(word) %>%
  filter(word != "applause") %>%
  anti_join(mystopwords2)%>%
  count(word) 
wordcloud(words = repub_word_cloud$word, freq = repub_word_cloud$n, min.freq = 2, 
          max.words = 200, random.order = FALSE, rot.per = 0.35, 
          color=brewer.pal(6, "Dark2"))

Repub_td <- Repub_Corpus %>%
  group_by(docnumber) %>%
  filter(word != "applause") %>%
  count(word) %>%
  select(word, n, docnumber)
Repub_td

Repub_dtm <- Repub_td %>%
  anti_join(mystopwords2) %>%
  cast_dtm(term = word,value = n, document = docnumber)
Repub_dtm 

n_topics <- c(2, 3, 4, 5, 10, 15, 25, 50)
Repub_comp <- n_topics %>%
  map(LDA, x = Repub_dtm, control = list())
data_frame(k = n_topics,
           perplex = map_dbl(Repub_comp, perplexity)) %>%
  ggplot(aes(k, perplex)) +
  geom_point() +
  geom_line()

repub_lda <- LDA(Repub_dtm, k = 10, control = list())
repub_lda

repub_lda_td <- tidy(repub_lda)

repub_terms <- repub_lda_td %>%
  group_by(topic) %>%
  top_n(15, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
repub_terms

perplexity(repub_lda)

repub_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic)))+
  geom_bar(stat= "identity", show.legend = FALSE)+
  facet_wrap(~topic, scales = "free")+
  coord_flip()
```

